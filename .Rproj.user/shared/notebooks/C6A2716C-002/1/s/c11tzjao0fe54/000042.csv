"0","mod_log0 <- logistic_reg("
"0","  penalty = 0.2 "
"0","  # I think that just defining penalty arbitrarily is what makes it not logistic lasso..?"
"0",") %>% "
"0","  set_mode(""classification"") %>% "
"0","  set_engine(""glmnet"")"
"0",""
"0","# Define data"
"0","election_log_df0 <- election %>% "
"0","  select(-i_republican_2016)"
"0",""
"0","# Recipe"
"0","rec_20 <- recipe(data = election_log_df0, i_republican_2016_f ~ .) %>% "
"0","  #step_select(-i_republican_2016) %>% "
"0","  update_role(fips, new_role = ""id"") %>% "
"0","  step_novel(county, state) %>% "
"0","  step_dummy(i_republican_2012, county, state) %>% "
"0","  step_normalize(all_numeric_predictors()) "
"0",""
"0","wkfl_log0 <- workflow() %>% "
"0","  add_model(mod_log0) %>% "
"0","  add_recipe(rec_20)"
"0",""
"0","# # Cross validating alphas and lambdas"
"0","# cv_log0 <- wkfl_log0 %>% "
"0","#   tune_grid("
"0","#     elec_cv,"
"0","#     grid = expand_grid(mixture = alphas, penalty = lambdas),"
"0","#     metrics = metric_set(accuracy)"
"0","#   )"
"0",""
"0","# cv_log0 %>% show_best()"
"0","# cv_log %>% collect_metrics()"
"0",""
"0","# Obtain Predictions"
"0","log_fit0 <- wkfl_log0 %>% "
"0","#  finalize_workflow(select_best(cv_log0, metric = 'accuracy')) %>% "
"0","  fit(data = election_log_df0)"
"2","Warning: [38;5;250m[33m![38;5;250m  The following columns have zero variance so scaling cannot be used: county_new and
  state_new.
[36mâ„¹[38;5;250m Consider using ]8;;ide:help:recipes::step_zv?step_zv]8;; to remove those columns before normalizing.[39m"
"0","log_pred0 = predict(log_fit0, new_data = election)"
"0",""
"0","election_log_df0 %<>% "
"0","  mutate("
"0","    pred = log_pred0$.pred_class"
"0","  )"
"0",""
"0","# Find accuracy, precision, specificity, sensitivity, ROC AUC"
"0",""
"0","accuracy(election_log_df0, i_republican_2016_f, pred)"
